{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B-POx15w81Zh"
   },
   "source": [
    "# CS273A Homework 2\n",
    "\n",
    "## Due Wednesday, October 16th, 11:59pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6EQP3cOK81Zk"
   },
   "source": [
    "---\n",
    "## Instructions\n",
    "\n",
    "\n",
    "This homework (and subsequent ones) will involve data analysis and reporting on methods and results\n",
    "using Python code. You will submit a **single PDF file** that contains everything to Gradescope. This includes any text you wish to include to describe your results, the complete code snippets of how you attempted each problem, any figures that were generated, and scans of any work on paper that you wish to include. It is important that you include enough detail that we know how you solved the problem, since otherwise we will be unable to grade it.\n",
    "\n",
    "Your homeworks will be given to you as Jupyter notebooks containing the problem descriptions and some template code that will help you get started. You are encouraged to use these starter Jupyter notebooks to complete your assignment and to write your report. This will help you not only ensure that all of the code for the solutions is included, but also will provide an easy way to export your results to a PDF file (for example, doing *print preview* and *printing to pdf*). I recommend liberal use of Markdown cells to create headers for each problem and sub-problem, explaining your implementation/answers, and including any mathematical equations. For parts of the homework you do on paper, scan it in such that it is legible (there are a number of free Android/iOS scanning apps, if you do not have access to a scanner), and include it as an image in the Jupyter notebook.\n",
    "\n",
    "**Double check that all of your answers are legible on Gradescope, e.g. make sure any text you have written does not get cut off.**\n",
    "\n",
    "If you have any questions/concerns about using Jupyter notebooks, ask us on EdD. If you decide not to use Jupyter notebooks, but go with Microsoft Word or LaTeX to create your PDF file, make sure that all of the answers can be generated from the code snippets included in the document.\n",
    "\n",
    "### Summary of Assignment: 100 total points\n",
    "- Problem 1: k-Nearest Neighbors (20 points)\n",
    "    - Problem 1.1: Splitting data into training & test sets (8 points)\n",
    "    - Problem 1.2: Plot predictions for different values of k (8 points)\n",
    "    - Problem 1.3: Display performance as a function of k & select best (4 points)\n",
    "    \n",
    "- Problem 2: Linear Regression (20 points)\n",
    "    - Problem 2.1: Train the model and plot the data along with its predictions (10 points)\n",
    "    - Problem 2.2: Compute the MSE loss for the training and evaluation data (10 points)\n",
    "    \n",
    "- Problem 3: Feature transformations (20 points)\n",
    "    - Problem 3.1: Train & display polynomial regression models using feature transforms (10 points)\n",
    "    - Problem 3.2: Plot the training & evaluation error as a function of degree (5 points)\n",
    "    - Problem 3.3: Select the best degree for these data (5 points)\n",
    "\n",
    "- Problem 4: Cross-Validation (20 points)\n",
    "    - Problem 4.1: Plot the five-fold cross validation error (10 points)\n",
    "    - Problem 4.2: Select the best degree using cross-validation (5 points)\n",
    "    - Problem 4.3: Compare cross-validation model selection to hold-out data (5 points)\n",
    "    \n",
    "- Problem 5: Regularization (15 points)\n",
    "    - Problem 5.1: Train L2-regularized linear regression ('Ridge regression') (5 points)\n",
    "    - Problem 5.2: Plot MSE as a function of the regularization amount (5 points)\n",
    "    - Problem 5.3: Select the best amount of regularization (5 points)\n",
    "    \n",
    "- Statement of Collaboration (5 points)\n",
    "\n",
    "<center> <img src=\"http://sli.ics.uci.edu/extras/sep.png\" alt=\"--------------------------------------------\" width=\"200px\" height=\"20px\" style=\"width:200px;height:20px;\"/> </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1730,
     "status": "ok",
     "timestamp": 1697235329787,
     "user": {
      "displayName": "Samuel Showalter",
      "userId": "14379346311603786226"
     },
     "user_tz": 420
    },
    "id": "Yunhun8a81Zl"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "from sklearn.linear_model import LinearRegression    # Basic Linear Regression\n",
    "from sklearn.linear_model import Ridge               # Linear Regression with L2 regularization\n",
    "\n",
    "from sklearn.model_selection import KFold            # Cross-validation tools\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures # Feature transformations\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline                # Useful for sequences of transforms\n",
    "\n",
    "import requests                                      # reading data\n",
    "from io import StringIO\n",
    "\n",
    "seed = 1234"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-sLGQzMG7bn"
   },
   "source": [
    "# Training / Test Splits\n",
    "\n",
    "As we've seen in lecture, it is difficult to tell how accurate our model is from only the data on which it has been trained.  For this reason, we usually reserve some data for evaluation, often called \"validation\" or \"test\" data.  We'll start by loading a one-dimensional regression data set to use in the rest of the homework.  We will divide this data set into 75% training data, and 25% evaluation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 916,
     "status": "ok",
     "timestamp": 1697235330700,
     "user": {
      "displayName": "Samuel Showalter",
      "userId": "14379346311603786226"
     },
     "user_tz": 420
    },
    "id": "wJZzm_xPG7bn"
   },
   "outputs": [],
   "source": [
    "url = 'https://www.ics.uci.edu/~ihler/classes/cs273/data/curve80.txt'\n",
    "\n",
    "with requests.get(url) as link: curve = np.genfromtxt(StringIO(link.text),delimiter=None)\n",
    "\n",
    "X = curve[:,0:-1]      # extract features\n",
    "Y = curve[:,-1]        # extract target values\n",
    "\n",
    "# split into training and evaluation data\n",
    "Xt, Xe, Yt, Ye = train_test_split(X, Y, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P1: K-Nearest Neighbors Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P1.1: Visualizing the Data Splits\n",
    "\n",
    "Plot the data for this regression problem, with the (scalar) feature $x$ along the horizontal axis, and the real-valued target $y$ as the vertical axis.  Plot all the data, displaying the training data $X_t$ in one color, and the evaluation data $X_e$ in a different color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P1.2 Visualizing KNN Regression Predictions\n",
    "\n",
    "Now use `sklearn`'s `KNeighborsRegressor` class to build a nearest neighbor regression model on your training data.  Build three models, using $k=1$, $k=5$, and $k=20$, and for each one display the training data, test data, and prediction function.  (Note: you can evaluate the prediction function of your learner by predicting at a dense collection of locations `x_spaced` along the x-axis, and then predicting at these points and connecting them using `plot`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with 1 row and 3 columns\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 3))\n",
    "\n",
    "x_spaced = np.linspace(0,9,100).reshape(-1,1)  # get a collection of x-locations at which to plot f(x)\n",
    "\n",
    "### YOUR CODE STARTS HERE ###\n",
    "\n",
    "for k in [1,5,20]:\n",
    "    knn = KNeighborsRegressor( # ...\n",
    "\n",
    "\n",
    "\n",
    "###  YOUR CODE ENDS HERE  ###\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P1.3: KNN Model Selection\n",
    "\n",
    "Train a model for each $k$ in $1 \\leq k \\leq 30$, and compute their training and validation MSE.  Plot these values as a function of $k$.  What is the best value of $k$ for your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = list(range(1,30))\n",
    "mse_train = []\n",
    "mse_eval = []\n",
    "\n",
    "for i,k in enumerate(k_values):\n",
    "\n",
    "    ### YOUR CODE STARTS HERE ###\n",
    "    knn = KNeighborsRegressor( # ...\n",
    "\n",
    "\n",
    "\n",
    "    ###  YOUR CODE ENDS HERE  ###\n",
    "\n",
    "plt.plot(k_values,mse_train,'b-', k_values,mse_eval,'g-', lw=3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JxWs6gpC81Zn"
   },
   "source": [
    "# P2: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-YbVDqs81Zo"
   },
   "source": [
    "### P2.1: Train linear regression model\n",
    "Now, let's train a simple linear regression model on the training data.  After training the model, plot the training data (colored blue), evaluation data (colored red), and our linear fit (a line) together on a single plot.  Also print out the coefficients (slope, `lr.coef_`, and intercept, `lr.intercept_`) of your model after fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XSHnKwRU81Zo"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "\n",
    "    ### YOUR CODE STARTS HERE ###\n",
    "\n",
    "lr = LinearRegression()...      # create and fit model to training data\n",
    "\n",
    "# to plot the prediction, we'll evaluate our model at a dense set of locations:\n",
    "x_spaced = np.linspace(0,10,200).reshape(-1,1)   # data points should be shape (m,1)\n",
    "yhat_spaced = lr.predict(x_spaced)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt...                         # plot the data and linear fit\n",
    "\n",
    "print(...                      # slope & intercept of your fit model\n",
    "\n",
    "    ###  YOUR CODE ENDS HERE  ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HnUKIV-681Zp"
   },
   "source": [
    "### P1.2 Evaluate your model's fit\n",
    "\n",
    "Compute the mean squared error of your trained model on the training data (the data it was fit on) and the held-out evaluation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ccnEYWLn81Zp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_zl3UfBK81Zp"
   },
   "source": [
    "## Problem 3: Feature Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKR20pOg81Zp"
   },
   "source": [
    "Often we will want to transform our data (as we saw in class).  A very simple version of this transformation is \"normalizing\" the data, in which we shift and scale the feature values to a desirable range; typically, zero mean and unit variance, for example.  The ``StandardScaler()`` object in scikit-learn implements such a transformation.\n",
    "\n",
    "Typically, a pre-processing transformation works in a similar way to training a model: we ``fit`` the object to our training data (in this case, computing the empirical mean and variance of the data), and save the parameters of the transformation (the shift and scale values) so that we can apply exactly the same transformation to subsequent data, for example when asked to predict on a new value of $x$.\n",
    "\n",
    "So, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ANJY0f081Zq"
   },
   "outputs": [],
   "source": [
    "scale = StandardScaler().fit(Xt)     # find the desired transformation\n",
    "X_transformed = scale.transform(Xt)  # & apply it to the training data\n",
    "\n",
    "# Now, we can train our model on X_transformed...\n",
    "# lr = LinearRegression()...\n",
    "\n",
    "# Before we predict, we also need to transform the test point's values:\n",
    "yhat_spaced = lr.predict(scale.transform(x_spaced))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBFr-LNAG7br"
   },
   "source": [
    "If you like (and as described in the Discussion code), you can use `sklearn`'s `Pipeline` object to simplify the process of sequentially applying transformations before a predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline( [('scale',StandardScaler()),('linreg',LinearRegression())])\n",
    "pipe.fit( ... )     # call fit on each element in the pipeline\n",
    "pipe.predict( ... ) # call transform on each element but last, then predict on the last "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NEgGaaE181Zq"
   },
   "source": [
    "## P3.1: Train polynomial regression models\n",
    "As mentioned in the homework, you can create additional features manually, e.g.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hBTYUSBJ81Zq"
   },
   "outputs": [],
   "source": [
    "m,n = Xt.shape            # rest of this cell assumes n=1 feature\n",
    "Xt2 = np.zeros((m,2))\n",
    "Xt2[:,0] = Xt[:,0]\n",
    "Xt2[:,1] = Xt[:,0]**2\n",
    "print (Xt.shape)\n",
    "print (Xt2.shape)\n",
    "print (Xt2[0:6,:])   # look at a few data points to check:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GefCpA9t81Zq"
   },
   "source": [
    "or, you can create them using SciKit's PolynomialFeatures transform object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r7ta_YJO81Zq"
   },
   "outputs": [],
   "source": [
    "Phi = PolynomialFeatures(degree=2,include_bias=False).fit(Xt)\n",
    "Xt2 = Phi.transform(Xt)\n",
    "print (Xt2[0:6,:])   # look at the same data points -- same values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3uGxLVHb81Zq"
   },
   "source": [
    "**Now, try fitting** a linear regression model using different numbers of polynomial features of $x$.\n",
    "\n",
    "For each degree $d \\in \\{0,1,3,5,7,10,15,18\\}$:\n",
    "\n",
    "- Fit a linear regression model using features consisting of all powers of $x$ up to degree $d$\n",
    "    - Make sure you apply ``StandardScaler`` to the transformed data before training\n",
    "- Plot the resulting prediction function $f(x)$, along with the training and validation data as before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yjlp-59t81Zr"
   },
   "outputs": [],
   "source": [
    "degrees = [0,1,3,5,7,10,15,18]\n",
    "learners = [ [] ]*len(degrees)\n",
    "\n",
    "fig, ax = plt.subplots(2,4, figsize=(24,10))\n",
    "\n",
    "for i,degree in enumerate(degrees):\n",
    "\n",
    "    ### YOUR CODE STARTS HERE ###\n",
    "\n",
    "    # Create a polynomial feature expansion of degree d\n",
    "\n",
    "    # Use StandardScaler to rescale the transformed data\n",
    "\n",
    "    # Fit your linear regression and save it to \"learners\"\n",
    "\n",
    "    axi = ax[i//4,i%4]\n",
    "    axi.plot( ... )  # plot the data and your prediction function\n",
    "    axi.set_ylim( ... )         # you'll want to set a consistent y-scale for comparison\n",
    "    axi.set_title( ... )        # don't forget to label your plots\n",
    "\n",
    "    ###  YOUR CODE ENDS HERE  ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "onhbJwo_81Zr"
   },
   "source": [
    "## P3.2 Model Performance\n",
    "Compute the mean squared error (MSE) loss of each of your trained models on both the training data and the evaluation data.  Plot these errors as a function of degree (so, degree along the horizontal axis, MSE loss as the vertical axis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BhWIoNDs81Zr"
   },
   "outputs": [],
   "source": [
    "mse_train = [0]*len(degrees)\n",
    "mse_test = [0]*len(degrees)\n",
    "\n",
    "for i,degree in enumerate(degrees):\n",
    "    # Recompute the degree-d poly transform if you didn't save it!\n",
    "    mse_train[i] = ...\n",
    "    mse_test[i] = ...\n",
    "\n",
    "plt.semilogy( ... )  # plot mse_train and mse_test as a function of the degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GFIfZT2O81Zr"
   },
   "source": [
    "## P3.3 Model Selection\n",
    "Which degree would you select to use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gRIz76DB81Zr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emd8mGqh81Zt"
   },
   "source": [
    "# P4: Cross-validation\n",
    "Cross validation is another method of model complexity assessment.  We use it only to determine the correct setting of complexity-altering parameters (\"hyperparameters\"), such as how many and which features to use, or parameters like \"k\" in KNN, for which training error alone provides little information.  In particular, cross validation will not produce a specific model (parameter values), only a setting of the hyperparameter values that cross-validation thinks will lead to a model (parameter values) with low test error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EI1Q-5vl81Zt"
   },
   "source": [
    "## P4.1:  5-Fold Cross-validation\n",
    "\n",
    "In the previous problem, we decided what degree of polynomial fit to use based on the performance on a held-out set of test data.  Now suppose that we do not have access to the target values of those data.  How can we determine the best degree?  \n",
    "\n",
    "We could perform another split; but since this is reducing the number of data available, let us instead use cross-validation to evaluate the degrees.  Cross-validation works by splitting the training data $X_T$ multiple times, one for eack of the $K$ partitions (``n_splits`` in the code), and repeat our entire training and evaluation procedure on each split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZBTa9ugr81Zt"
   },
   "outputs": [],
   "source": [
    "mse_xval = [ 0. ]*len(degrees)\n",
    "\n",
    "for j,degree in enumerate(degrees):   # loop over desired degree values\n",
    "\n",
    "    ### YOUR CODE STARTS HERE ###\n",
    "\n",
    "    xval = KFold(n_splits = 5)      # split into k=5 splits\n",
    "\n",
    "    for train_index, val_index in xval.split(Xt):\n",
    "        # Extract the ith cross-validation fold (training/validation split)\n",
    "        Xti,Xvi,Yti,Yvi = Xt[train_index],Xt[val_index],Yt[train_index],Yt[val_index]\n",
    "\n",
    "        # Now, build the model:\n",
    "        # Create a polynomial feature expansion\n",
    "        # Create a StandardScaler\n",
    "        # Fit the linear regression model on the training folds, Xti/Yti\n",
    "        # Compute the MSE on the evaluation fold, Xvi/Yvi\n",
    "\n",
    "    # Evaluate the quality of this degree by averaging the MSE across the five folds\n",
    "\n",
    "\n",
    "# Plot the estimated MSE from cross-validation as a function of the degree\n",
    "plt.semilogy( ...\n",
    "             \n",
    "    ###  YOUR CODE ENDS HERE  ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5h-HDelS81Zt"
   },
   "source": [
    "## P4.2: Cross-validation model selection\n",
    "\n",
    "What degree would you choose based on the cross validation performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5-j6IVnP81Zt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADHV2h_581Zt"
   },
   "source": [
    "## P4.3 Comparison to test performance\n",
    "\n",
    "How do the MSE estimates from 5-fold cross-validation compare to the estimated test performance you found from your held-out data, $X_E$?  Explain briefly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xZ1DiXtI81Zt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P5 : Regularization\n",
    "\n",
    "In systems where we already have a lot of features, or where we do not know which of the many features we might construct will be helpful, we can use regularization to help us control overfitting.\n",
    "\n",
    "## P5.1: Regularized Regression\n",
    "In `sklearn`, linear regression with quadratic (L2) regularization is implemented in a different object, `Ridge`.  Use this ridge regression model to fit your degree-18 data using various amounts of regularization:\n",
    "$$ \\alpha \\in \\{10^{-20},10^{-12},10^{-8},10^{-6},10^{-4},0.01,0.1,1.0\\}$$\n",
    "Plot the training and evaluation data, along with the predicted regression function for each value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [1e-20, 1e-12, 1e-8, 1e-6, 1e-4, 1e-2, 1e-1, 1.]\n",
    "learners = [ None ]*len(alphas)\n",
    "\n",
    "fig, ax = plt.subplots(2,4, figsize=(24,10))\n",
    "\n",
    "for i,alpha in enumerate(alphas):\n",
    "\n",
    "    ### YOUR CODE STARTS HERE ###\n",
    "    pipe = Pipeline( ... )   # define your high-dim transform, scaling, and ridge regression learner\n",
    "\n",
    "    # Fit your learner and save it to your list\n",
    "    learners[i] = ...\n",
    "    \n",
    "    axi = ax[i//4,i%4]\n",
    "    axi.plot( ... )             # plot the data and your prediction function\n",
    "    axi.set_ylim( ... )         # you'll want to set a consistent y-scale for comparison\n",
    "    axi.set_title( ... )        # don't forget to label your plots\n",
    "\n",
    "    ###  YOUR CODE ENDS HERE  ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P5.2: Training and Test Performance\n",
    "\n",
    "Using your trained models, evaluate the training and test MSE as a function of the regularization $\\alpha$.  Plot these functions. (It is best to use a log-scale for both alpha and MSE, for clarity.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_train = [0]*len(alphas)\n",
    "mse_test = [0]*len(alphas)\n",
    "\n",
    "for i,alpha in enumerate(alphas):\n",
    "    mse_train[i] = ...\n",
    "    mse_test[i] = ... \n",
    "\n",
    "plt.loglog( ... );  # plot mse_train and mse_test as a function of the regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P5.3: Model Selection\n",
    "Which regularization value $\\alpha$ would you select?  Identify in which regions $\\alpha$ is underfitting or overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nsh5OORd81Zt"
   },
   "source": [
    "---\n",
    "### Statement of Collaboration (5 points)\n",
    "\n",
    "It is **mandatory** to include a Statement of Collaboration in each submission, with respect to the guidelines below. Include the names of everyone involved in the discussions (especially in-person ones), and what was discussed.\n",
    "\n",
    "All students are required to follow the academic honesty guidelines posted on the course website. For\n",
    "programming assignments, in particular, I encourage the students to organize (perhaps using EdD) to\n",
    "discuss the task descriptions, requirements, bugs in my code, and the relevant technical content before they start\n",
    "working on it. However, you should not discuss the specific solutions, and, as a guiding principle, you are not\n",
    "allowed to take anything written or drawn away from these discussions (i.e. no photographs of the blackboard,\n",
    "written notes, referring to EdD, etc.). Especially after you have started working on the assignment, try\n",
    "to restrict the discussion to EdD as much as possible, so that there is no doubt as to the extent of your\n",
    "collaboration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NYHwS-LO81Zu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
